<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Greg Gandenberger">
<meta name="dcterms.date" content="2019-11-20">

<title>blog - Evaluating Classification Models, Part 2: The Sufficiency of Precision and Recall</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Evaluating Classification Models, Part 2: The Sufficiency of Precision and Recall</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ml</div>
                <div class="quarto-category">evals</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Greg Gandenberger </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 20, 2019</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="district.webp" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">With high recall, most dresses appear in the dress feed. With high precision, most products in the dress feed are dresses. Are those two numbers all we need?</figcaption><p></p>
</figure>
</div>
<p>This post is part of a series on evaluating classification models:</p>
<ul>
<li><a href="../../posts/2019-11-14_evaluating-classifier-pt1/evaluating_classifiers_pt_1.html"><strong>Part 1: Weighing False Positives Against False Negatives</strong></a> explains why we need systematic ways to evaluate classification models.</li>
<li><a href="../../posts/2019-11-20_evaluating-classifiers-pt2/evaluating_classifiers_pt_2.html"><strong>Part 2: The Sufficiency of Precision and Recall</strong></a> explains why <em>precision</em> and <em>recall</em> are sufficient for evaluating classification models in typical cases.</li>
<li><a href="../../posts/2019-11-26_evaluating-classifiers-pt3/evaluating_classifiers_pt_3.html"><strong>Part 3: <span class="math inline">\(F_\beta\)</span> and Other Weighted Pythagorean Means of Precision and Recall</strong></a> explains what patterns of preferences are encoded by the <em>Pythagorean means</em> of precision and recall. This class of metrics includes the popular <span class="math inline">\(F_\beta\)</span> family, among others.</li>
<li><a href="../../posts/2019-12-02_evaluating-classifiers-pt4/evaluating_classifiers_pt_4.html"><strong>Part 4: Weighted Power Means of Precision and Recall</strong></a> generalizes beyond the Pythagorean means to the broader class of <em>weighted power means</em> of precision and recall.</li>
</ul>
<p>This series differs from other discussions of evaluation metrics for classification models in that it aims to provide a <strong>systematic perspective</strong>. Rather than providing a laundry list of individual metrics, it situates those metrics within a fairly comprehensive family and explains how you can choose a member of that family that is appropriate for your use case.</p>
<p><a href="../../posts/2019-11-14_evaluating-classifier-pt1/evaluating_classifiers_pt_1.html">Part 1</a> of this series explains why we need metrics that allow us to evaluate binary classification models systematically. For instance, if we are developing a model that takes images of a product in ShopRunner’s retailer network and returns a probability that the product is a dress, we need a metric that weighs false positives (products that are predicted to be dresses but are not) against false negatives (products that are dresses but are predicted not to be) in a way that approximately matches what our preferences over models would be upon sufficient reflection.</p>
<p>That post put forward <em>precision</em> and <em>recall</em> as ways to measure the ability of a model to avoid false positives and false negatives, respectively, using the example of a model that classifies a product as either a dress or not. Precision is the accuracy of a model’s positive predictions. For instance, when it says that a product is a dress, how often is it actually a dress? Recall is the accuracy of the model’s predictions for actual instances of the positive class. For instance, when a product is a dress, how often does the model classify it as a dress?</p>
<p>Precision and recall are useful metrics, but in order to use them to rank models we need some way to combine them into a single measure of overall performance. Subsequent posts in this series will go into detail about how to think about such composite metrics. This post addresses a prior question: <strong>why use precision and recall as our starting points for model evaluation?</strong> In particular, how can we be sure that those numbers do not leave out important information?</p>
<section id="summarizing-model-performance-with-precision-and-recall" class="level2">
<h2 class="anchored" data-anchor-id="summarizing-model-performance-with-precision-and-recall">Summarizing Model Performance with Precision and Recall</h2>
<p>The results of applying a binary classifier to a dataset can be displayed in a confusion matrix:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Predicted No</th>
<th>Predicted Yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Actual No</td>
<td>|True Negative|</td>
<td>|False Positive|</td>
</tr>
<tr class="even">
<td>Actual Yes</td>
<td>|False Negative|</td>
<td>|True Positive|</td>
</tr>
</tbody>
</table>
<p>where e.g.&nbsp;“|True Positive|” refers to the number of true positive predictions that the model generates (i.e., where the model correctly predicted that the item in question belongs to the positive class).</p>
<p>For instance, a model that classifies a product as “dress” or “not a dress” might have the following confusion matrix:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Predicted No</th>
<th>Predicted Yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Actual No</td>
<td>92</td>
<td>8</td>
</tr>
<tr class="even">
<td>Actual Yes</td>
<td>10</td>
<td>90</td>
</tr>
</tbody>
</table>
<p><strong>We often act as if an observed confusion matrix contains everything we can learn about the value of a model from its performance on a test dataset.</strong> This approach is not always justified: for instance, the confusion matrix discards information about the presence or absence of problematic patterns of error such as racial biases. However, if those kinds of problems are being addressed by other means, then the assumption that a confusion matrix is a sufficient basis for preferences over models may be justified.</p>
<p>We can calculate precision and recall from a confusion matrix but not vice versa. However, when we evaluate a model against a validation dataset, we typically have access to the total number of positive and negative examples (the row sums in the confusion matrix). Given that information, we <em>can</em> reconstruct a confusion matrix from precision and recall (See the Appendix to this post.) Thus, in a typical scenario, <strong>precision and recall contain the same information as a confusion matrix</strong>, so they are sufficient for evaluating a model if the confusion matrix is.</p>
<p>Now, there are other pairs of numbers that also contain the same information as a confusion matrix given the numbers of actual positive and actual negative cases, such as sensitivity and specificity. The choice among such pairs of numbers is a matter of taste. I use precision and recall because they are popular in the machine learning community. I suspect that they are also easier for people to understand than some of the alternatives because they have actual positive or predicted positive cases in the denominator, so that thinking about them requires processing fewer negations.</p>
<p>In any case, <strong>precision and recall are sufficient for model evaluation when a confusion matrix is sufficient for model evaluation and the numbers of actual positive and actual negative examples in the dataset are known.</strong></p>
</section>
<section id="appendix-constructing-a-confusion-matrix-from-precision-recall-and-its-row-sums" class="level2">
<h2 class="anchored" data-anchor-id="appendix-constructing-a-confusion-matrix-from-precision-recall-and-its-row-sums">Appendix: Constructing a Confusion Matrix from Precision, Recall, and its Row Sums</h2>
<p>Here is one way to reconstruct a confusion matrix from precision, recall, and the number of “Actual No” and “Actual Yes” cases.</p>
<section id="true-positive" class="level3">
<h3 class="anchored" data-anchor-id="true-positive">|True Positive|</h3>
<p><span class="math display">\[
\text{Recall} = \frac{|\text{True Positive}|}{|\text{Actual Yes}|}
\]</span></p>
<p>so</p>
<p><span class="math display">\[
|\text{True Positive}| = \text{Recall} \times |\text{Actual Yes}|
\]</span></p>
</section>
<section id="false-negative" class="level3">
<h3 class="anchored" data-anchor-id="false-negative">|False Negative|</h3>
<p><span class="math display">\[
|\text{False Negative}| = |\text{Actual Yes}| - |\text{True Positive}|
\]</span></p>
</section>
<section id="false-positive" class="level3">
<h3 class="anchored" data-anchor-id="false-positive">|False Positive|</h3>
<p><span class="math display">\[
\text{Precision} = \frac{|\text{True Positive}|}{|\text{True Positive}| + |\text{False Positive}|}
\]</span></p>
<p>so a bit of algebra shows</p>
<p><span class="math display">\[
|\text{False Positive}| = |\text{True Positive}|\frac{1-\text{Precision}}{\text{Precision}}
\]</span></p>
</section>
<section id="true-negative" class="level3">
<h3 class="anchored" data-anchor-id="true-negative">|True Negative|</h3>
<p><span class="math display">\[
|\text{True Negative}| = |\text{Actual No}| - |\text{False Positive}|
\]</span></p>
</section>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>Thanks to Nicole Carlson, Ali Vanderveld, and the rest of the ShopRunner data science team for comments on earlier versions of this material.</p>
<p><em>Originally published at <a href="https://medium.com/shoprunner/evaluating-classification-models-2-64e9e21f9038">medium.com</a></em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>