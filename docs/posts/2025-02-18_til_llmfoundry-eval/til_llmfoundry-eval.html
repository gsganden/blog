<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Greg Gandenberger">
<meta name="dcterms.date" content="2025-02-18">

<title>Blog - TIL: How LLM Foundry Evaluates Performance On Open-Ended Math Problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://hypothes.is/embed.js"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">TIL: How LLM Foundry Evaluates Performance On Open-Ended Math Problems</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">ml</div>
                <div class="quarto-category">llms</div>
                <div class="quarto-category">evals</div>
                <div class="quarto-category">math-verify</div>
                <div class="quarto-category">llm-foundry</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Greg Gandenberger </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 18, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a <a href="https://dev.to/jbranchaud/how-i-built-a-learning-machine-45k9">TIL</a> (“Today I Learned”) post. I expect it to be useful to my future self and maybe to others, but it is meant to be a quick, informal way to capture something I learned rather than a polished presentation.</p>
</div>
</div>
<section id="context" class="level1">
<h1>Context</h1>
<p>I am contributing to a research project on <a href="posts/2025-02-14_fine-tuning-on-regression-task/fine_tuning_on_regression_tasks.html">performance-efficient fine tuning of LLMs</a>. That project involves fine tuning LLMs on math problems.</p>
</section>
<section id="problem" class="level1">
<h1>Problem</h1>
<p><strong>Evaluating LLM performance on open-ended math problems is difficult because LLMs can generate arbitrary text.</strong> Checking an LLM’s answer to an open-ended (as opposed to multiple-choice, for instance) math problem against ground truth requires extracting its answer from the generated text and then accounting for issues such as rounding (e.g.&nbsp;0.33 vs.&nbsp;0.333) and alternative representations (e.g.&nbsp;0.33 vs.&nbsp;1/3). HuggingFace recently released the <a href="https://github.com/huggingface/math-verify">Math-Verify library</a> to address these issues and <a href="https://huggingface.co/blog/math_verify_leaderboard">showed that it makes a massive difference</a> to LLM math leaderboards.</p>
<p>In the meantime, we have been using <a href="https://github.com/mosaicml/llm-foundry">LLM Foundry</a> for model development. <strong>LLM Foundry has its own procedure for evaluating LLM math performance. By default, it simply <a href="https://github.com/mosaicml/llm-foundry/blob/e03b23d9342471a2464a6500c509bd657381d32c/llmfoundry/eval/metrics/nlp.py#L198-L201">checks whether LLM’s output starts with an exact match to one of a set of provided answers</a></strong> after <a href="https://github.com/mosaicml/llm-foundry/blob/e03b23d9342471a2464a6500c509bd657381d32c/llmfoundry/eval/metrics/nlp.py#L133">some light post-processing</a> to “lower text and remove punctuation, articles and extra whitespace”.</p>
<p><strong>This approach does not always give the desired result.</strong> For instance, in this case the model seems to be generating multiple-choice options rather than answering the question. The first of those options matches the ground truth answer, so this evaluation procedure counts it as correct even though the model did not commit to it as its actual answer. (All of the examples below come from <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-135M">SmolLM2-135M</a> on <a href="https://github.com/mosaicml/llm-foundry/blob/main/scripts/eval/local_data/symbolic_problem_solving/gsm8k.jsonl">GSM8K</a>. SmolLM2-135M is a base language model and is tiny by LLM standards, so it is not expected to perform well on these problems.)</p>
<div class="callout-example callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Question:</strong> When Freda cooks canned tomatoes into sauce, they lose half their volume. Each 16 ounce can of tomatoes that she uses contains three tomatoes. Freda’s last batch of tomato sauce made 32 ounces of sauce. How many tomatoes did Freda use?</li>
<li><strong>Model Output:</strong> “12\nB: 16\nC: 24\nD: 32”</li>
<li><strong>Ground Truth:</strong> “12”</li>
<li><strong>Evaluation:</strong> Correct</li>
</ul>
</div>
</div>
<p>Another case leads to a comedy of errors: the model gets a numerically correct answer for entirely wrong reasons, and the evaluation procedure counts it as correct for the wrong reason.</p>
<div class="callout-example callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Question:</strong> Uriah’s book bag is getting too heavy for him. He needs to remove 15 pounds from it. His comic books weigh 1/4 pound each and his toys weigh 1/2 pound each. If he removes 30 comic books, how many toys does he need to remove?</li>
<li><strong>Model Output:</strong> “15 pounds x 1/4 pounds x 1/2 pounds = 15 pounds.”</li>
<li><strong>Ground Truth:</strong> “15”</li>
<li><strong>Evaluation:</strong> Correct</li>
</ul>
</div>
</div>
<p>In another case, the model gives the right answer, but the evaluation procedure counts it as incorrect because it does not put that answer at the start of its output.</p>
<div class="callout-example callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Question:</strong> Mico and Marco wanted to get to know each other. They realized that the sum of their ages is 20. What will be the sum of their ages in 10 years?</li>
<li><strong>Model Output:</strong> “20 + 20 = 40”</li>
<li><strong>Ground Truth:</strong> “40”</li>
<li><strong>Evaluation:</strong> Incorrect</li>
</ul>
</div>
</div>
</section>
<section id="next-steps" class="level1">
<h1>Next Steps</h1>
<p>We should be able to do better. LLM Foundry supports specifing a “metric” to use to evaluate the model’s performance. The <a href="https://github.com/mosaicml/llm-foundry/blob/e03b23d9342471a2464a6500c509bd657381d32c/llmfoundry/utils/builders.py#L587-L590">default</a> metric for “generation_task_with_answers” (which is at least how <a href="https://github.com/mosaicml/llm-foundry/blob/e03b23d9342471a2464a6500c509bd657381d32c/scripts/eval/yamls/tasks_v0.3.yaml#L6">scripts/eval/yamls/tasks_v0.3.yaml</a> treats GSM8K) is <a href="https://github.com/mosaicml/llm-foundry/blob/e03b23d9342471a2464a6500c509bd657381d32c/llmfoundry/eval/metrics/nlp.py#L92"><code>InContextLearningGenerationExactMatchAccuracy</code></a>. We could define a custom metric that uses <code>Math-Verify</code> to extract the LLM’s answer and compare it to ground truth more accurately.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>